{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9759ea0a-ee91-4bac-be87-eb28283488ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 18:59:33.316955: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-08 18:59:33.382585: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-08 18:59:33.384091: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-08 18:59:34.444508: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import load_img,img_to_array\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Flatten , Conv2D \n",
    "from keras.layers import  MaxPooling2D ,BatchNormalization , Dropout\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d74f8cb7-11c3-448d-a350-d0673453ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (32,32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9af7579-b00c-4859-bced-f88b7fc12220",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = os.listdir('/home/zkzk/Arabic Handwritten/train')\n",
    "x_test = os.listdir('/home/zkzk/Arabic Handwritten/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b378a65-ac4d-460e-b8c9-7877d6fa166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgView = 'id_label_9.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35f1c60e-12c9-4a66-9738-e7a7ac1c02a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_Alphabet = ['alef', 'beh', 'teh', 'theh', 'jeem', 'hah', 'khah', 'dal', 'thal',\n",
    "                    'reh', 'zain', 'seen', 'sheen', 'sad', 'dad', 'tah', 'zah', 'ain',\n",
    "                    'ghain', 'feh', 'qaf', 'kaf', 'lam', 'meem', 'noon', 'heh', 'waw', 'yeh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79396475-c141-40a5-b2e0-a4779eac4426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_', '9.png']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arabic_Alphabet[int(imgView.split('label_')[1].split('.')[0])]\n",
    "imgView.split('label_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f4aee08-9fd6-4e09-a470-ba409a0b6659",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainLB = pd.read_csv('TrainLabel.csv')\n",
    "TestLB = pd.read_csv('TestLabel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1350636-b9bb-4f6c-bde2-798804ed5acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1\n",
       "0  1\n",
       "1  1\n",
       "2  1\n",
       "3  1\n",
       "4  1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainLB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b63cb316-a62f-46f0-90ca-3519d05710ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train 13440\n"
     ]
    }
   ],
   "source": [
    "y_train= []\n",
    "for filename in x_train:\n",
    "    y_train.append(filename.split('label_')[1].split('.')[0])\n",
    "print(\"Size of train\",len(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0795bc74-f4e2-423c-9c29-9a6639041260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test 3361\n"
     ]
    }
   ],
   "source": [
    "y_test=[]\n",
    "for name in x_test:\n",
    "    y_test.append(name.split('label_')[-1].split('.')[0])\n",
    "print(\"Size of test\",len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4fda4f2-76fe-4100-b7cd-5f2bec919d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train , y_train , test_size = .15 , random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "93364904-d4be-4321-97ae-1f34a5148738",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame({\n",
    "    'filename': x_train,\n",
    "    'category': y_train\n",
    "})\n",
    "validation = pd.DataFrame({\n",
    "    'filename': x_valid,\n",
    "    'category': y_valid\n",
    "})\n",
    "test = pd.DataFrame({\n",
    "    'filename': x_test,\n",
    "    'category': y_test\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2b383391-0ecc-47d9-8116-6106a133d218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2394\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test)):\n",
    "    if test['category'][i] == '':\n",
    "        print(i)\n",
    "test['filename']["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5d45c9f7-7e73-4ee5-a865-9db2f3218f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refrances(category):\n",
    "    x = arabic_Alphabet[int(category)-1]\n",
    "    return x\n",
    "def drop_empty(df , col_name):\n",
    "    df[col_name].replace('' , np.nan , inplace = True)\n",
    "    df.dropna(subset = col_name , inplace = True)\n",
    "drop_empty(train , 'category')\n",
    "drop_empty(validation , 'category')\n",
    "drop_empty(test , 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2d6cc0f1-bc8d-41c0-8d26-01e1ad75dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['category'] = train['category'].apply(refrances)\n",
    "validation['category'] = validation['category'].apply(refrances)\n",
    "test['category'] = test['category'].apply(refrances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "897da516-9d07-4d8b-8a0b-a784e3d5d213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd0e6b8e310>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgShow = load_img('./train/' + x_train[2])\n",
    "plt.title('it is Character ' + refrances(y_train[2]))\n",
    "plt.imshow(imgShow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b6d0f79-d658-4e89-8e88-2fa78572e0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd10f4a5f10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgShow = load_img('./train/' + x_train[6])\n",
    "plt.title('it is Character ' + refrances(y_train[6]))\n",
    "plt.imshow(imgShow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "134da9d0-6262-4a33-bd6d-13c953f109db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 30, 30, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 13, 13, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4, 4, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 2, 2, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2, 2, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 28)                924       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,972\n",
      "Trainable params: 94,332\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# install model\n",
    "classifier = Sequential()\n",
    "\n",
    "# 1- convolution\n",
    "classifier.add(Conv2D(32,(3,3),input_shape = size , activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "# 2- pooling image\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "#3-  Adding a second convolutional layer\n",
    "classifier.add(Conv2D(64,(3,3), activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.2)) #used for prevent overfitting model\n",
    "#3-  Adding a third convolutional layer\n",
    "classifier.add(Conv2D(64,(3,3), activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection and hidden layers\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dense(units = 32, activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units = 28, activation = 'softmax'))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy'\n",
    "                   , metrics = ['accuracy'])\n",
    "classifier.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8555cd33-7c60-4b73-8d14-85583fccbf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11424 validated image filenames belonging to 28 classes.\n",
      "Found 2016 validated image filenames belonging to 28 classes.\n"
     ]
    }
   ],
   "source": [
    "batch = 64\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_set = train_datagen.flow_from_dataframe( train , './train',\n",
    "            x_col='filename',\n",
    "            y_col='category',\n",
    "            target_size=(32,32),\n",
    "            color_mode=\"grayscale\",\n",
    "            class_mode='categorical',\n",
    "            batch_size=batch\n",
    "          )\n",
    "valid_set = train_datagen.flow_from_dataframe(\n",
    "    validation, './train',\n",
    "            x_col='filename',\n",
    "            y_col='category',\n",
    "            target_size=(32,32),\n",
    "            color_mode=\"grayscale\",\n",
    "            class_mode='categorical',\n",
    "            batch_size=batch\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0332a3f4-16d1-4806-a077-412eb906a6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "len(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cb430a3-f3b6-4033-b9e9-b436b89adb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 18:59:38.112115: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - ETA: 0s - loss: 3.4160 - accuracy: 0.0985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 18:59:58.816801: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 22s 109ms/step - loss: 3.4160 - accuracy: 0.0985 - val_loss: 4.6393 - val_accuracy: 0.0451\n",
      "Epoch 2/100\n",
      "179/179 [==============================] - 19s 104ms/step - loss: 2.6966 - accuracy: 0.2026 - val_loss: 4.0455 - val_accuracy: 0.0610\n",
      "Epoch 3/100\n",
      "179/179 [==============================] - 19s 107ms/step - loss: 2.3030 - accuracy: 0.2966 - val_loss: 2.5837 - val_accuracy: 0.2312\n",
      "Epoch 4/100\n",
      "179/179 [==============================] - 18s 102ms/step - loss: 2.0207 - accuracy: 0.3701 - val_loss: 1.6063 - val_accuracy: 0.5382\n",
      "Epoch 5/100\n",
      "179/179 [==============================] - 18s 102ms/step - loss: 1.7795 - accuracy: 0.4474 - val_loss: 1.3734 - val_accuracy: 0.5863\n",
      "Epoch 6/100\n",
      "179/179 [==============================] - 19s 104ms/step - loss: 1.5970 - accuracy: 0.4953 - val_loss: 1.1285 - val_accuracy: 0.6627\n",
      "Epoch 7/100\n",
      "179/179 [==============================] - 19s 104ms/step - loss: 1.4499 - accuracy: 0.5382 - val_loss: 1.0238 - val_accuracy: 0.7093\n",
      "Epoch 8/100\n",
      "179/179 [==============================] - 19s 104ms/step - loss: 1.3551 - accuracy: 0.5667 - val_loss: 0.9299 - val_accuracy: 0.7257\n",
      "Epoch 9/100\n",
      "179/179 [==============================] - 19s 104ms/step - loss: 1.2556 - accuracy: 0.5988 - val_loss: 0.8340 - val_accuracy: 0.7460\n",
      "Epoch 10/100\n",
      "179/179 [==============================] - 18s 103ms/step - loss: 1.1929 - accuracy: 0.6159 - val_loss: 0.7838 - val_accuracy: 0.7659\n",
      "Epoch 11/100\n",
      "179/179 [==============================] - 18s 103ms/step - loss: 1.1486 - accuracy: 0.6337 - val_loss: 0.7563 - val_accuracy: 0.7693\n",
      "Epoch 12/100\n",
      "179/179 [==============================] - 20s 114ms/step - loss: 1.0997 - accuracy: 0.6451 - val_loss: 0.9303 - val_accuracy: 0.7039\n",
      "Epoch 13/100\n",
      "179/179 [==============================] - 19s 106ms/step - loss: 1.0342 - accuracy: 0.6659 - val_loss: 0.7244 - val_accuracy: 0.7798\n",
      "Epoch 14/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 1.0325 - accuracy: 0.6694 - val_loss: 0.7619 - val_accuracy: 0.7579\n",
      "Epoch 15/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.9917 - accuracy: 0.6804 - val_loss: 0.6673 - val_accuracy: 0.7937\n",
      "Epoch 16/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.9545 - accuracy: 0.6976 - val_loss: 0.7126 - val_accuracy: 0.7773\n",
      "Epoch 17/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.9369 - accuracy: 0.6988 - val_loss: 0.5559 - val_accuracy: 0.8328\n",
      "Epoch 18/100\n",
      "179/179 [==============================] - 19s 108ms/step - loss: 0.8920 - accuracy: 0.7150 - val_loss: 0.6061 - val_accuracy: 0.8100\n",
      "Epoch 19/100\n",
      "179/179 [==============================] - 18s 99ms/step - loss: 0.8611 - accuracy: 0.7302 - val_loss: 0.5397 - val_accuracy: 0.8383\n",
      "Epoch 20/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.8526 - accuracy: 0.7346 - val_loss: 0.5131 - val_accuracy: 0.8497\n",
      "Epoch 21/100\n",
      "179/179 [==============================] - 18s 102ms/step - loss: 0.8195 - accuracy: 0.7412 - val_loss: 0.5149 - val_accuracy: 0.8408\n",
      "Epoch 22/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.8247 - accuracy: 0.7418 - val_loss: 0.4843 - val_accuracy: 0.8552\n",
      "Epoch 23/100\n",
      "179/179 [==============================] - 19s 105ms/step - loss: 0.8035 - accuracy: 0.7481 - val_loss: 0.4857 - val_accuracy: 0.8517\n",
      "Epoch 24/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.7749 - accuracy: 0.7532 - val_loss: 0.5044 - val_accuracy: 0.8576\n",
      "Epoch 25/100\n",
      "179/179 [==============================] - 18s 102ms/step - loss: 0.7649 - accuracy: 0.7635 - val_loss: 0.4996 - val_accuracy: 0.8487\n",
      "Epoch 26/100\n",
      "179/179 [==============================] - 18s 102ms/step - loss: 0.7379 - accuracy: 0.7682 - val_loss: 0.4791 - val_accuracy: 0.8408\n",
      "Epoch 27/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.7282 - accuracy: 0.7718 - val_loss: 0.4239 - val_accuracy: 0.8785\n",
      "Epoch 28/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.7177 - accuracy: 0.7757 - val_loss: 0.6085 - val_accuracy: 0.7956\n",
      "Epoch 29/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.6960 - accuracy: 0.7816 - val_loss: 0.4432 - val_accuracy: 0.8591\n",
      "Epoch 30/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.6762 - accuracy: 0.7918 - val_loss: 0.4186 - val_accuracy: 0.8676\n",
      "Epoch 31/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.6909 - accuracy: 0.7863 - val_loss: 0.4049 - val_accuracy: 0.8770\n",
      "Epoch 32/100\n",
      "179/179 [==============================] - 19s 103ms/step - loss: 0.6673 - accuracy: 0.7932 - val_loss: 0.4157 - val_accuracy: 0.8824\n",
      "Epoch 33/100\n",
      "179/179 [==============================] - 19s 104ms/step - loss: 0.6751 - accuracy: 0.7946 - val_loss: 0.4234 - val_accuracy: 0.8715\n",
      "Epoch 34/100\n",
      "179/179 [==============================] - 18s 102ms/step - loss: 0.6419 - accuracy: 0.8016 - val_loss: 0.3987 - val_accuracy: 0.8819\n",
      "Epoch 35/100\n",
      "179/179 [==============================] - 19s 105ms/step - loss: 0.6277 - accuracy: 0.8015 - val_loss: 0.4146 - val_accuracy: 0.8661\n",
      "Epoch 36/100\n",
      "179/179 [==============================] - 18s 102ms/step - loss: 0.6403 - accuracy: 0.8036 - val_loss: 0.3958 - val_accuracy: 0.8819\n",
      "Epoch 37/100\n",
      "179/179 [==============================] - 18s 102ms/step - loss: 0.6275 - accuracy: 0.8035 - val_loss: 0.3731 - val_accuracy: 0.8899\n",
      "Epoch 38/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.6221 - accuracy: 0.8085 - val_loss: 0.3992 - val_accuracy: 0.8740\n",
      "Epoch 39/100\n",
      "179/179 [==============================] - 18s 102ms/step - loss: 0.6115 - accuracy: 0.8158 - val_loss: 0.3660 - val_accuracy: 0.8924\n",
      "Epoch 40/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.5863 - accuracy: 0.8170 - val_loss: 0.4062 - val_accuracy: 0.8710\n",
      "Epoch 41/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.5988 - accuracy: 0.8135 - val_loss: 0.3433 - val_accuracy: 0.8899\n",
      "Epoch 42/100\n",
      "179/179 [==============================] - 18s 102ms/step - loss: 0.5840 - accuracy: 0.8197 - val_loss: 0.3695 - val_accuracy: 0.8874\n",
      "Epoch 43/100\n",
      "179/179 [==============================] - 18s 102ms/step - loss: 0.5727 - accuracy: 0.8234 - val_loss: 0.3598 - val_accuracy: 0.8919\n",
      "Epoch 44/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.5781 - accuracy: 0.8248 - val_loss: 0.3720 - val_accuracy: 0.8869\n",
      "Epoch 45/100\n",
      "179/179 [==============================] - 18s 100ms/step - loss: 0.5778 - accuracy: 0.8251 - val_loss: 0.3680 - val_accuracy: 0.8919\n",
      "Epoch 46/100\n",
      "179/179 [==============================] - 18s 99ms/step - loss: 0.5571 - accuracy: 0.8283 - val_loss: 0.3518 - val_accuracy: 0.8983\n",
      "Epoch 47/100\n",
      "179/179 [==============================] - 18s 100ms/step - loss: 0.5453 - accuracy: 0.8329 - val_loss: 0.3603 - val_accuracy: 0.8958\n",
      "Epoch 48/100\n",
      "179/179 [==============================] - 18s 102ms/step - loss: 0.5609 - accuracy: 0.8264 - val_loss: 0.3489 - val_accuracy: 0.8948\n",
      "Epoch 49/100\n",
      "179/179 [==============================] - 18s 102ms/step - loss: 0.5375 - accuracy: 0.8346 - val_loss: 0.3319 - val_accuracy: 0.9053\n",
      "Epoch 50/100\n",
      "179/179 [==============================] - 18s 102ms/step - loss: 0.5615 - accuracy: 0.8248 - val_loss: 0.3368 - val_accuracy: 0.8993\n",
      "Epoch 51/100\n",
      "179/179 [==============================] - 18s 103ms/step - loss: 0.5315 - accuracy: 0.8406 - val_loss: 0.3482 - val_accuracy: 0.8958\n",
      "Epoch 52/100\n",
      "179/179 [==============================] - 19s 107ms/step - loss: 0.5302 - accuracy: 0.8348 - val_loss: 0.3291 - val_accuracy: 0.9058\n",
      "Epoch 53/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.5229 - accuracy: 0.8388 - val_loss: 0.4362 - val_accuracy: 0.8710\n",
      "Epoch 54/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.5355 - accuracy: 0.8332 - val_loss: 0.3297 - val_accuracy: 0.9008\n",
      "Epoch 55/100\n",
      "179/179 [==============================] - 18s 102ms/step - loss: 0.5099 - accuracy: 0.8438 - val_loss: 0.3117 - val_accuracy: 0.9013\n",
      "Epoch 56/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.5258 - accuracy: 0.8370 - val_loss: 0.3424 - val_accuracy: 0.8919\n",
      "Epoch 57/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.5060 - accuracy: 0.8435 - val_loss: 0.3478 - val_accuracy: 0.8983\n",
      "Epoch 58/100\n",
      "179/179 [==============================] - 18s 103ms/step - loss: 0.5081 - accuracy: 0.8447 - val_loss: 0.3404 - val_accuracy: 0.8998\n",
      "Epoch 59/100\n",
      "179/179 [==============================] - 18s 99ms/step - loss: 0.5175 - accuracy: 0.8404 - val_loss: 0.3126 - val_accuracy: 0.9072\n",
      "Epoch 60/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.4997 - accuracy: 0.8445 - val_loss: 0.3397 - val_accuracy: 0.9003\n",
      "Epoch 61/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.5028 - accuracy: 0.8441 - val_loss: 0.3432 - val_accuracy: 0.8978\n",
      "Epoch 62/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.5004 - accuracy: 0.8486 - val_loss: 0.3251 - val_accuracy: 0.8998\n",
      "Epoch 63/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.4992 - accuracy: 0.8467 - val_loss: 0.2886 - val_accuracy: 0.9112\n",
      "Epoch 64/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.5036 - accuracy: 0.8460 - val_loss: 0.3497 - val_accuracy: 0.8943\n",
      "Epoch 65/100\n",
      "179/179 [==============================] - 19s 103ms/step - loss: 0.4863 - accuracy: 0.8521 - val_loss: 0.2866 - val_accuracy: 0.9132\n",
      "Epoch 66/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.4794 - accuracy: 0.8521 - val_loss: 0.3300 - val_accuracy: 0.9008\n",
      "Epoch 67/100\n",
      "179/179 [==============================] - 18s 103ms/step - loss: 0.4829 - accuracy: 0.8543 - val_loss: 0.2841 - val_accuracy: 0.9112\n",
      "Epoch 68/100\n",
      "179/179 [==============================] - 18s 103ms/step - loss: 0.4833 - accuracy: 0.8506 - val_loss: 0.2992 - val_accuracy: 0.9127\n",
      "Epoch 69/100\n",
      "179/179 [==============================] - 18s 103ms/step - loss: 0.4805 - accuracy: 0.8550 - val_loss: 0.4262 - val_accuracy: 0.8596\n",
      "Epoch 70/100\n",
      "179/179 [==============================] - 18s 102ms/step - loss: 0.4781 - accuracy: 0.8541 - val_loss: 0.3046 - val_accuracy: 0.9053\n",
      "Epoch 71/100\n",
      "179/179 [==============================] - 19s 104ms/step - loss: 0.4809 - accuracy: 0.8534 - val_loss: 0.2986 - val_accuracy: 0.9033\n",
      "Epoch 72/100\n",
      "179/179 [==============================] - 19s 104ms/step - loss: 0.4692 - accuracy: 0.8555 - val_loss: 0.2917 - val_accuracy: 0.9137\n",
      "Epoch 73/100\n",
      "179/179 [==============================] - 18s 102ms/step - loss: 0.4770 - accuracy: 0.8506 - val_loss: 0.2975 - val_accuracy: 0.9053\n",
      "Epoch 74/100\n",
      "179/179 [==============================] - 18s 103ms/step - loss: 0.4586 - accuracy: 0.8585 - val_loss: 0.2888 - val_accuracy: 0.9152\n",
      "Epoch 75/100\n",
      "179/179 [==============================] - 18s 103ms/step - loss: 0.4561 - accuracy: 0.8599 - val_loss: 0.3018 - val_accuracy: 0.9167\n",
      "Epoch 76/100\n",
      "179/179 [==============================] - 19s 106ms/step - loss: 0.4621 - accuracy: 0.8571 - val_loss: 0.3099 - val_accuracy: 0.9013\n",
      "Epoch 77/100\n",
      "179/179 [==============================] - 18s 102ms/step - loss: 0.4651 - accuracy: 0.8602 - val_loss: 0.3090 - val_accuracy: 0.9053\n",
      "Epoch 78/100\n",
      "179/179 [==============================] - 18s 102ms/step - loss: 0.4643 - accuracy: 0.8598 - val_loss: 0.2902 - val_accuracy: 0.9147\n",
      "Epoch 79/100\n",
      "179/179 [==============================] - 18s 100ms/step - loss: 0.4666 - accuracy: 0.8585 - val_loss: 0.3130 - val_accuracy: 0.9018\n",
      "Epoch 80/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.4593 - accuracy: 0.8589 - val_loss: 0.3137 - val_accuracy: 0.9023\n",
      "Epoch 81/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.4494 - accuracy: 0.8566 - val_loss: 0.2737 - val_accuracy: 0.9162\n",
      "Epoch 82/100\n",
      "179/179 [==============================] - 18s 100ms/step - loss: 0.4520 - accuracy: 0.8612 - val_loss: 0.3156 - val_accuracy: 0.9033\n",
      "Epoch 83/100\n",
      "179/179 [==============================] - 18s 100ms/step - loss: 0.4409 - accuracy: 0.8664 - val_loss: 0.2999 - val_accuracy: 0.9122\n",
      "Epoch 84/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.4516 - accuracy: 0.8609 - val_loss: 0.2907 - val_accuracy: 0.9092\n",
      "Epoch 85/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.4530 - accuracy: 0.8613 - val_loss: 0.2775 - val_accuracy: 0.9191\n",
      "Epoch 86/100\n",
      "179/179 [==============================] - 18s 99ms/step - loss: 0.4400 - accuracy: 0.8649 - val_loss: 0.2981 - val_accuracy: 0.9127\n",
      "Epoch 87/100\n",
      "179/179 [==============================] - 18s 99ms/step - loss: 0.4384 - accuracy: 0.8648 - val_loss: 0.2722 - val_accuracy: 0.9177\n",
      "Epoch 88/100\n",
      "179/179 [==============================] - 18s 100ms/step - loss: 0.4397 - accuracy: 0.8673 - val_loss: 0.2809 - val_accuracy: 0.9191\n",
      "Epoch 89/100\n",
      "179/179 [==============================] - 18s 100ms/step - loss: 0.4309 - accuracy: 0.8717 - val_loss: 0.2890 - val_accuracy: 0.9162\n",
      "Epoch 90/100\n",
      "179/179 [==============================] - 18s 99ms/step - loss: 0.4275 - accuracy: 0.8711 - val_loss: 0.3002 - val_accuracy: 0.9107\n",
      "Epoch 91/100\n",
      "179/179 [==============================] - 18s 99ms/step - loss: 0.4591 - accuracy: 0.8604 - val_loss: 0.2810 - val_accuracy: 0.9182\n",
      "Epoch 92/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.4401 - accuracy: 0.8660 - val_loss: 0.2896 - val_accuracy: 0.9058\n",
      "Epoch 93/100\n",
      "179/179 [==============================] - 18s 100ms/step - loss: 0.4244 - accuracy: 0.8707 - val_loss: 0.2997 - val_accuracy: 0.9127\n",
      "Epoch 94/100\n",
      "179/179 [==============================] - 18s 100ms/step - loss: 0.4257 - accuracy: 0.8696 - val_loss: 0.2937 - val_accuracy: 0.9177\n",
      "Epoch 95/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.4426 - accuracy: 0.8604 - val_loss: 0.2706 - val_accuracy: 0.9276\n",
      "Epoch 96/100\n",
      "179/179 [==============================] - 18s 100ms/step - loss: 0.4178 - accuracy: 0.8772 - val_loss: 0.2688 - val_accuracy: 0.9206\n",
      "Epoch 97/100\n",
      "179/179 [==============================] - 18s 101ms/step - loss: 0.4309 - accuracy: 0.8727 - val_loss: 0.2769 - val_accuracy: 0.9241\n",
      "Epoch 98/100\n",
      "179/179 [==============================] - 18s 99ms/step - loss: 0.4208 - accuracy: 0.8728 - val_loss: 0.3040 - val_accuracy: 0.9102\n",
      "Epoch 99/100\n",
      "179/179 [==============================] - 18s 99ms/step - loss: 0.4253 - accuracy: 0.8730 - val_loss: 0.2749 - val_accuracy: 0.9182\n",
      "Epoch 100/100\n",
      "179/179 [==============================] - 18s 100ms/step - loss: 0.4153 - accuracy: 0.8768 - val_loss: 0.2817 - val_accuracy: 0.9182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd10d3a03d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_set,\n",
    "          steps_per_epoch = int(len(train_set)),\n",
    "          epochs = int(100),\n",
    "          validation_data = valid_set,\n",
    "          validation_steps=int(len(valid_set))\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21e09961-f879-4b11-807a-843a4797ddd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3360 validated image filenames belonging to 28 classes.\n",
      " 12/336 [>.............................] - ETA: 4s - loss: 0.1430 - accuracy: 0.9333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 19:40:04.121324: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 4s 12ms/step - loss: 0.2073 - accuracy: 0.9375\n",
      "\n",
      " Test accuracy: 93.75\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_dataframe(\n",
    "    test, \n",
    "    \"./test\", \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=(32,32),\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode='categorical',\n",
    "    batch_size=10\n",
    ")\n",
    "score=classifier.evaluate(test_set)\n",
    "print('\\n', 'Test accuracy:', score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4173fb10-45f3-4ea0-8048-2e1f466609e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = dict((v,k) for k,v in train_set.class_indices.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20db4b15-e3f6-4850-b070-cf06f9aa71cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "sample = np.random.choice(x_test)\n",
    "test_img = load_img(('./test/' + sample ), color_mode='grayscale')\n",
    "img=img_to_array(test_img).reshape(-1,32,32,1)\n",
    "predict=classifier.predict(img)\n",
    "predict=np.argmax(predict,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d58c3744-2e94-4dd2-9c63-f13ec8d10d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd0e45861f0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imgShow = load_img('./train/' + x_train[6])\n",
    "plt.title('it is Character ' + refrances(predict[0]))\n",
    "plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63b71733-76d9-44ad-aacf-085f66b2447c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3360 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_dataframe(\n",
    "    test, \n",
    "    \"./test\", \n",
    "    x_col='filename',\n",
    "    target_size=(32,32),\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c472b9fa-3b4c-43f4-9298-2dc57a92a977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8/105 [=>............................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 20:13:32.876904: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 2s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "predict=classifier.predict(test_set)\n",
    "predict=np.argmax(predict,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd3291e3-17b9-41b3-b84f-57608695b64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3361"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)\n",
    "# print(refrances(predict[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "56e89ccf-2c11-4ef9-b413-d6132c66d40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3360\n"
     ]
    }
   ],
   "source": [
    "y_p=[]\n",
    "for i in range(len(y_test)):\n",
    "    y_p.append(label_map[predict[i-1]])\n",
    "for i in range(len(y_p)):\n",
    "    if i == 2394: #we drop axise num i  becouse the has an empty category in test\n",
    "        y_p.remove(y_p[i])\n",
    "print(len(y_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9c126487-347b-400f-bb36-db0d1d71e5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        dad\n",
       "1        beh\n",
       "2        lam\n",
       "3       theh\n",
       "4       zain\n",
       "        ... \n",
       "3356     lam\n",
       "3357     feh\n",
       "3358     sad\n",
       "3359     reh\n",
       "3360     hah\n",
       "Name: category, Length: 3360, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be8c40-7ccf-4da0-a51a-c416dd7a1312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "90f41d25-cf75-431d-9bc2-ae6af01b1306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[108,   1,   0,   0,   1,   0,   4,   3,   0,   0,   0,   0,   1,\n",
       "          1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,   0,\n",
       "          0,   0],\n",
       "       [  0, 117,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n",
       "          2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0, 117,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0],\n",
       "       [  0,   0,   1, 112,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   1,   0,   0,   3,   0,   0,   1,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 109,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,   2,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   2,   0, 110,   1,   0,   1,   0,   0,   0,   0,\n",
       "          0,   1,   6,   0,   0,   1,   0,   0,   1,   1,   0,   0,   2,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 112,   0,   0,   0,   0,   6,   0,\n",
       "          0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  1,   0,   0,   1,   0,   0,   0, 111,   0,   3,   0,   1,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 113,   0,   1,   0,   0,\n",
       "          1,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   1,   0,\n",
       "          0,   0],\n",
       "       [  2,   0,   0,   0,   0,   0,   0,   5,   0, 113,   0,   1,   0,\n",
       "          0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   3,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 111,   0,   1,\n",
       "          0,   1,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  3,   0,   0,   0,   0,   0,   3,   0,   0,   0,   0, 112,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   1,   0, 116,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   0,   1,\n",
       "          0,   1],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        113,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   3,   0,   0,   0,   0,   4,   0,   0,\n",
       "          0, 114,   1,   0,   0,   0,   0,   0,   3,   0,   2,   0,   1,\n",
       "          0,   1],\n",
       "       [  1,   0,   0,   0,   0,   4,   0,   0,   0,   1,   1,   0,   0,\n",
       "          0,   0, 109,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  1,   1,   0,   0,   8,   0,   0,   0,   1,   0,   0,   0,   0,\n",
       "          0,   0,   0, 114,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "          0,  12],\n",
       "       [  0,   0,   1,   2,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n",
       "          1,   0,   1,   0, 113,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   6, 118,   0,   0,   0,   0,   1,   0,   1,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   1,   0,   2,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,   0,   0,   0,   0, 111,   0,   0,   0,   0,   0,   1,\n",
       "          0,   1],\n",
       "       [  1,   0,   0,   0,   1,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 117,   0,   1,   0,   0,   0,\n",
       "          6,   0],\n",
       "       [  0,   0,   1,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,\n",
       "          0,   2,   2,   0,   0,   0,   0,   0, 112,   0,   8,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0, 108,   0,   0,   0,\n",
       "          0,   5],\n",
       "       [  0,   1,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   4,   0,   3,   0, 107,   0,   0,\n",
       "          0,   2],\n",
       "       [  3,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,   0,   0,\n",
       "          2,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0, 112,   1,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 108,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0,\n",
       "        113,   0],\n",
       "       [  0,   0,   0,   1,   0,   0,   0,   0,   0,   1,   0,   0,   0,\n",
       "          0,   1,   1,   4,   0,   0,   0,   0,   0,   4,   0,   0,   0,\n",
       "          0,  98]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_p,test['category'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1766c2be-8026-497e-b01e-8ee86ab6757a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9306753942279083\n"
     ]
    }
   ],
   "source": [
    "accuracy = sum(cm[i][i] for i in range(28)) / len(y_test)\n",
    "print(\"accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c2271444-22e5-44b8-8cb9-24304cc12b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 21:16:47.809265: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,15,15,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-08 21:16:47.831290: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,6,6,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-08 21:16:47.852458: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,2,2,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-08 21:16:47.886028: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-08 21:16:48.834140: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,15,15,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-08 21:16:48.925517: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,6,6,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-08 21:16:49.024112: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,2,2,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-08 21:16:49.223074: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: arabic_character_prediction/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: arabic_character_prediction/assets\n"
     ]
    }
   ],
   "source": [
    "classifier.save('arabic_character_prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473f4aca-a5d2-46df-9e12-8d599340c525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
