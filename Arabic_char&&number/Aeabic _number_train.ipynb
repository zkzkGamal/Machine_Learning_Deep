{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6204082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Flatten , Conv2D , MaxPooling2D ,BatchNormalization , Dropout\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085ef5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = pd.read_csv('./train_img.csv')\n",
    "train_label = pd.read_csv('./train_label.csv')\n",
    "test_img = pd.read_csv('./test_img.csv')\n",
    "test_label = pd.read_csv('./test_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fd3eb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  2\n",
       "2  3\n",
       "3  4\n",
       "4  5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf67a9cd",
   "metadata": {},
   "source": [
    "# to get the values from dataFrame \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b18abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_img.values\n",
    "x_test = test_img.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ac5ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59999, 784)\n",
      "(9999, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447a9585",
   "metadata": {},
   "source": [
    "# Normalize the data to make CNN faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b33d7de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test = (x_train / 255.0) ,(x_test / 255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ee0afd",
   "metadata": {},
   "source": [
    "# then reshape the img to size number , 32w ,32h ,1d \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c72f0a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train  = x_train.reshape(x_train.shape[0] , 28 , 28 , 1 )\n",
    "x_test  = x_test.reshape(x_test.shape[0] , 28 , 28 ,1)\n",
    "x_test.shape\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f698df",
   "metadata": {},
   "source": [
    "# split data train into train and valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a44fa304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train1 , x_valid , y_train1 , y_valid = train_test_split(x_train , train_label , test_size=.2 , random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcf24ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47999, 28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4064b1",
   "metadata": {},
   "source": [
    "# encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f39b5892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9999, 10)\n",
      "(47999, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train1 = to_categorical(y_train1, num_classes = 10)\n",
    "y_valid  = to_categorical(y_valid , num_classes = 10)\n",
    "y_test = to_categorical(test_label , num_classes=10)\n",
    "print(y_test.shape)\n",
    "print(y_train1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638ed74f",
   "metadata": {},
   "source": [
    "# image fixing and visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8e5d696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2190c11edd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = (x_test[35][:,:,0])\n",
    "image = image.reshape([28, 28])\n",
    "image = np.fliplr(image)\n",
    "image = np.rot90(image)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b4b900",
   "metadata": {},
   "source": [
    "# finally the step of building CNN model to predict numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15155de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 26, 26, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 13, 13, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 11, 11, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 32)          18464     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 3, 3, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 1, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1, 1, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               8448      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,618\n",
      "Trainable params: 63,722\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# install model\n",
    "classifier = Sequential()\n",
    "\n",
    "# 1- convolution\n",
    "classifier.add(Conv2D(32,(3,3),input_shape = (28, 28, 1), activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "# 2- pooling image\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.1))\n",
    "\n",
    "#3-  Adding a second convolutional layer\n",
    "classifier.add(Conv2D(64,(3,3), activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.1)) #used for prevent overfitting model\n",
    "\n",
    "#3-  Adding a third convolutional layer\n",
    "classifier.add(Conv2D(32,(3,3),input_shape = (28, 28, 1) ,  activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.2))\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection and hidden layers\n",
    "classifier.add(Dense(units = 256, activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dense(units = 64, activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(0.25))\n",
    "classifier.add(Dense(units = 10, activation = 'softmax'))\n",
    "\n",
    "# Compiling the CNN\n",
    "from tensorflow.keras.optimizers import SGD,RMSprop\n",
    "optimizer = SGD(lr = 0.001 , momentum=0.30)\n",
    "classifier.compile(optimizer = optimizer , loss = 'categorical_crossentropy'\n",
    "                   , metrics = ['accuracy'])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fba7def2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\zkzk\\anaconda3\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: pydot in c:\\users\\zkzk\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\zkzk\\anaconda3\\lib\\site-packages (from pydot) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz\n",
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84123c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(classifier, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
    "# from IPython.display import Image\n",
    "# Image(\"model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7e3ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "callbacks = [earlystop]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3fbeda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "st_pr_ep = int(len(x_train1) / 256)\n",
    "vl_step = int(len(x_valid) / 256)\n",
    "print(st_pr_ep)\n",
    "print(vl_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b251be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "187/187 [==============================] - 54s 282ms/step - loss: 0.6053 - accuracy: 0.8229 - val_loss: 2.7999 - val_accuracy: 0.2615\n",
      "Epoch 2/30\n",
      "187/187 [==============================] - 52s 279ms/step - loss: 0.2152 - accuracy: 0.9446 - val_loss: 1.7456 - val_accuracy: 0.4503\n",
      "Epoch 3/30\n",
      "187/187 [==============================] - 52s 281ms/step - loss: 0.1572 - accuracy: 0.9579 - val_loss: 0.1920 - val_accuracy: 0.9497\n",
      "Epoch 4/30\n",
      "187/187 [==============================] - 55s 296ms/step - loss: 0.1283 - accuracy: 0.9664 - val_loss: 0.0719 - val_accuracy: 0.9791\n",
      "Epoch 5/30\n",
      "187/187 [==============================] - 60s 322ms/step - loss: 0.1119 - accuracy: 0.9698 - val_loss: 0.0576 - val_accuracy: 0.9828\n",
      "Epoch 6/30\n",
      "187/187 [==============================] - 53s 283ms/step - loss: 0.1016 - accuracy: 0.9732 - val_loss: 0.0555 - val_accuracy: 0.9829\n",
      "Epoch 7/30\n",
      "187/187 [==============================] - 56s 299ms/step - loss: 0.0928 - accuracy: 0.9753 - val_loss: 0.0492 - val_accuracy: 0.9852\n",
      "Epoch 8/30\n",
      "187/187 [==============================] - 55s 294ms/step - loss: 0.0858 - accuracy: 0.9772 - val_loss: 0.0481 - val_accuracy: 0.9860\n",
      "Epoch 9/30\n",
      "187/187 [==============================] - 57s 307ms/step - loss: 0.0783 - accuracy: 0.9785 - val_loss: 0.0431 - val_accuracy: 0.9877\n",
      "Epoch 10/30\n",
      "187/187 [==============================] - 94s 504ms/step - loss: 0.0760 - accuracy: 0.9795 - val_loss: 0.0420 - val_accuracy: 0.9874\n",
      "Epoch 11/30\n",
      "187/187 [==============================] - 77s 410ms/step - loss: 0.0698 - accuracy: 0.9810 - val_loss: 0.0408 - val_accuracy: 0.9880\n",
      "Epoch 12/30\n",
      "187/187 [==============================] - 64s 345ms/step - loss: 0.0688 - accuracy: 0.9806 - val_loss: 0.0386 - val_accuracy: 0.9887\n",
      "Epoch 13/30\n",
      "187/187 [==============================] - 56s 301ms/step - loss: 0.0671 - accuracy: 0.9815 - val_loss: 0.0374 - val_accuracy: 0.9885\n",
      "Epoch 14/30\n",
      "187/187 [==============================] - 54s 290ms/step - loss: 0.0610 - accuracy: 0.9827 - val_loss: 0.0362 - val_accuracy: 0.9895\n",
      "Epoch 15/30\n",
      "187/187 [==============================] - 60s 324ms/step - loss: 0.0573 - accuracy: 0.9843 - val_loss: 0.0350 - val_accuracy: 0.9897\n",
      "Epoch 16/30\n",
      "187/187 [==============================] - 56s 298ms/step - loss: 0.0560 - accuracy: 0.9850 - val_loss: 0.0341 - val_accuracy: 0.9908\n",
      "Epoch 17/30\n",
      "187/187 [==============================] - 53s 283ms/step - loss: 0.0564 - accuracy: 0.9845 - val_loss: 0.0334 - val_accuracy: 0.9906\n",
      "Epoch 18/30\n",
      "187/187 [==============================] - 57s 303ms/step - loss: 0.0538 - accuracy: 0.9847 - val_loss: 0.0325 - val_accuracy: 0.9906\n",
      "Epoch 19/30\n",
      "187/187 [==============================] - 68s 362ms/step - loss: 0.0522 - accuracy: 0.9858 - val_loss: 0.0329 - val_accuracy: 0.9905\n",
      "Epoch 20/30\n",
      "187/187 [==============================] - 57s 303ms/step - loss: 0.0496 - accuracy: 0.9861 - val_loss: 0.0313 - val_accuracy: 0.9912\n",
      "Epoch 21/30\n",
      "187/187 [==============================] - 59s 313ms/step - loss: 0.0489 - accuracy: 0.9863 - val_loss: 0.0310 - val_accuracy: 0.9914\n",
      "Epoch 22/30\n",
      "187/187 [==============================] - 58s 313ms/step - loss: 0.0477 - accuracy: 0.9874 - val_loss: 0.0313 - val_accuracy: 0.9913\n",
      "Epoch 23/30\n",
      "187/187 [==============================] - 53s 286ms/step - loss: 0.0452 - accuracy: 0.9876 - val_loss: 0.0307 - val_accuracy: 0.9918\n",
      "Epoch 24/30\n",
      "187/187 [==============================] - 61s 329ms/step - loss: 0.0457 - accuracy: 0.9869 - val_loss: 0.0298 - val_accuracy: 0.9919\n",
      "Epoch 25/30\n",
      "187/187 [==============================] - 64s 343ms/step - loss: 0.0435 - accuracy: 0.9883 - val_loss: 0.0296 - val_accuracy: 0.9921\n",
      "Epoch 26/30\n",
      "187/187 [==============================] - 64s 343ms/step - loss: 0.0438 - accuracy: 0.9875 - val_loss: 0.0290 - val_accuracy: 0.9922\n",
      "Epoch 27/30\n",
      "187/187 [==============================] - 57s 305ms/step - loss: 0.0434 - accuracy: 0.9881 - val_loss: 0.0295 - val_accuracy: 0.9921\n",
      "Epoch 28/30\n",
      "187/187 [==============================] - 58s 309ms/step - loss: 0.0412 - accuracy: 0.9886 - val_loss: 0.0284 - val_accuracy: 0.9925\n",
      "Epoch 29/30\n",
      "187/187 [==============================] - 53s 284ms/step - loss: 0.0397 - accuracy: 0.9888 - val_loss: 0.0276 - val_accuracy: 0.9925\n",
      "Epoch 30/30\n",
      "187/187 [==============================] - 56s 302ms/step - loss: 0.0399 - accuracy: 0.9885 - val_loss: 0.0278 - val_accuracy: 0.9927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2190ccb1d50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = classifier.fit( x_train1 , \n",
    "               y_train1 , \n",
    "               epochs = 30 , \n",
    "               steps_per_epoch= st_pr_ep , \n",
    "               callbacks= callbacks , \n",
    "               validation_data=(x_valid , y_valid),\n",
    "               validation_steps= vl_step )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d482bdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "y_pred=np.argmax(y_pred,axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f895f83a",
   "metadata": {},
   "source": [
    "# Graph that describe the loss and accuracy of the training set and the validation set (Training and validation curves)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8e3f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Draw the loss and accuracy curves of the training set and the validation set.\n",
    "# # Can judge whether it is under-fitting or over-fitting\n",
    "# fig, ax = plt.subplots(2,1)\n",
    "# ax[0].plot(history.history['loss'][0], color='b', label=\"Training loss\")\n",
    "# ax[0].plot(history.history['val_loss'][0], color='r', label=\"validation loss\",axes =ax[0])\n",
    "# legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "# ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "# ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "# legend = ax[1].legend(loc='best', shadow=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b2efb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_lab = pd.read_csv('./test_label.csv')\n",
    "\n",
    "test_la = test_lab.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a543c7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix , accuracy_score\n",
    "cm = confusion_matrix(test_la,y_pred)\n",
    "acc = accuracy_score(test_la , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "817ac832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6],\n",
       "       [7],\n",
       "       [8],\n",
       "       [9],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_la[0:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e0a8745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33583beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :   0.9881988198819882\n"
     ]
    }
   ],
   "source": [
    "print('accuracy :  ' , acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2449639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 11ms/step - loss: 0.0420 - accuracy: 0.9882\n",
      "\n",
      " test accourcy :  98.81988167762756\n",
      "\n",
      " test1 loss :  0.04201770946383476\n"
     ]
    }
   ],
   "source": [
    "score = classifier.evaluate(x_test , y_test )\n",
    "print('\\n' , 'test accourcy : ' , score[1]*100)\n",
    "print('\\n' , 'test1 loss : ' , score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd2fe7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('Arabic_number_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75adcbd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
